//
//  TicketScannerView.swift
//  YeonMyu
//
//  Created by ë°•ì„±ë¯¼ on 8/10/25.
//

import SwiftUI
import VisionKit
import Vision
import ChatGPTSwift

struct TicketScannerView : View
{
    let cameraService = CameraService()
    @Binding var capturedImage : UIImage?
    
    @Environment(\.presentationMode) private var presentationMode
    let openAI = ChatGPTAPI(apiKey: APIKey.openAIKey)
    
    var body: some View{
        ZStack{
            CameraView(cameraService: cameraService) { result in
                switch result{
                case .success(let photo):
                    if let data = photo.fileDataRepresentation() {
                        capturedImage = UIImage(data: data)
                        presentationMode.wrappedValue.dismiss()
                        
                        if let cgImage = UIImage(data: data)?.cgImage {
                            let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])
                            let request = VNRecognizeTextRequest { request, error in
                                if let error = error {
                                    print("âŒ OCR Error: \(error.localizedDescription)")
                                    return
                                }
                                
                                guard let observations = request.results as? [VNRecognizedTextObservation] else {
                                    print("âŒ No text found.")
                                    return
                                }
                                var ocrStr = ""
                                for observation in observations {
                                    if let topCandidate = observation.topCandidates(1).first {
                                        print("ğŸ“„ ì¸ì‹ëœ í…ìŠ¤íŠ¸: \(topCandidate.string)")
                                        ocrStr += topCandidate.string + "\n"
                                    }
                                }
                                Task {
                                    do {
                                        let scanModel = try await sendGPTAI(texts: ocrStr)
                                        let scanRequest = try await NetworkManager.shared.requestPerformance(date: scanModel.date, title: scanModel.name)
                                        for i in scanRequest {
                                            print(i)
                                        }
                                    } catch {
                                        print("ì¸ì¦ ì˜¤ë¥˜ ã… ")
                                    }
                                }
                                
                            }
                            
                            request.recognitionLevel = .accurate
                            request.recognitionLanguages = ["ko-KR", "en-US"]
                            request.usesLanguageCorrection = true
                            
                            DispatchQueue.global(qos: .userInitiated).async {
                                do {
                                    try handler.perform([request])
                                } catch {
                                    print("âŒ OCR ì²˜ë¦¬ ì‹¤íŒ¨: \(error.localizedDescription)")
                                }
                            }
                        }
                    } else {
                        print("Error: no image data found")
                    }
                case .failure(let err):
                    print(err.localizedDescription)
                }
            }
            VStack{
                Spacer()
                Button(action: {
                    cameraService.capturePhoto()
                }, label: {Image(systemName: "circle").font(.system(size: 72)).foregroundColor(.white)})
            }
        } //:VSTACK
    }
}

extension TicketScannerView {
    /// OpenAIì— í…ìŠ¤íŠ¸ ë³´ë‚´ê¸°
    func sendGPTAI(texts: String) async throws -> TicketScanResult {
        do {
            let result = try await openAI.sendMessageStream(text: texts, model: .gpt_hyphen_3_period_5_hyphen_turbo, systemText: "ë³´ë‚¸ í…ìŠ¤íŠ¸ ì¤‘ì— ê³µì—°ëª…, ê´€ëŒë‚ ì§œ ì¶”ì¶œí•´ì„œ JSON í˜•ì‹ìœ¼ë¡œ ì „ë‹¬í•´ì¤˜ ê³µì—°ëª… ë³€ìˆ˜ëª…ì€ name, ë‚ ì§œ ë³€ìˆ˜ëª…ì€ dateë¡œ ë³´ë‚´ì¤˜. ë‚ ì§œí˜•ì‹ì€ yyyyMMdd")
            var responseText = ""
            for try await line in result {
                responseText += line
            }
            guard let data = parseJSONResponse(responseText) else { throw "ì˜¤ë¥˜" }
            return data
        } catch {
            throw "ì˜¤ë¥˜"
        }
    }
    
    
    func parseJSONResponse(_ jsonString: String) -> TicketScanResult? {
        guard let jsonData = jsonString.data(using: .utf8) else {
            print("âŒ ë¬¸ìì—´ì„ Dataë¡œ ë³€í™˜ ì‹¤íŒ¨")
            return nil
        }
        
        do {
            let decoded = try JSONDecoder().decode(TicketScanResult.self, from: jsonData)
            return decoded
        } catch {
            print("âŒ JSON ë””ì½”ë”© ì‹¤íŒ¨: \(error.localizedDescription)")
            return nil
        }
    }
    
    
    
}
